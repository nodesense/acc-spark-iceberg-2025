{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1648f9bb-ba46-4250-ae1d-cf5bfe5b793f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.catalog.iceberg\", \"org.apache.iceberg.spark.SparkCatalog\")\n",
    "spark.conf.set(\"spark.sql.catalog.iceberg.type\", \"hadoop\")\n",
    "spark.conf.set(\"spark.sql.catalog.iceberg.warehouse\", \"gs://tpch-source/iceberg_warehouse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bf7a4b4-8ce6-4aa9-af58-3723c55422b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|      catalog|\n",
      "+-------------+\n",
      "|spark_catalog|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW CATALOGS\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47f42923-041e-498f-85cf-10fa2261e337",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE NAMESPACE IF NOT EXISTS iceberg.tpch\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83fe5d6f-b861-4967-9e45-25303a626c43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS iceberg.tpch.products (\n",
    "    product_id INT,\n",
    "    name STRING,\n",
    "    price DECIMAL(10,2)\n",
    ") USING ICEBERG\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fc0e8ff-5ed4-4ffc-88fe-c4ff5d584d9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "INSERT INTO iceberg.tpch.products VALUES\n",
    "(1, 'Laptop', 999.99),\n",
    "(2, 'Phone', 499.99),\n",
    "(3, 'Tablet', 299.99)\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c24c267-5c8e-4603-8d23-5a0761be31a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+------+\n",
      "|product_id|  name| price|\n",
      "+----------+------+------+\n",
      "|         1|Laptop|999.99|\n",
      "|         2| Phone|499.99|\n",
      "|         3|Tablet|299.99|\n",
      "+----------+------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM iceberg.tpch.products\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bebb0b81-e5a3-4ffe-a8f4-e27800c2f814",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "MERGE INTO iceberg.tpch.products t\n",
    "USING (SELECT 1 AS product_id, 1099.99 AS price) s\n",
    "ON t.product_id = s.product_id\n",
    "WHEN MATCHED THEN UPDATE SET t.price = s.price\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "058b4a00-5c98-4ba9-b7c7-2d729958b05e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+-------+\n",
      "|product_id|  name|  price|\n",
      "+----------+------+-------+\n",
      "|         1|Laptop|1099.99|\n",
      "|         2| Phone| 499.99|\n",
      "|         3|Tablet| 299.99|\n",
      "+----------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM iceberg.tpch.products\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40faade9-ad2e-4cd3-b63b-1175baad4942",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"DELETE FROM iceberg.tpch.products WHERE name = 'Tablet'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87281305-d318-49d8-8b5c-f575d07c852c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+-------+\n",
      "|product_id|  name|  price|\n",
      "+----------+------+-------+\n",
      "|         1|Laptop|1099.99|\n",
      "|         2| Phone| 499.99|\n",
      "+----------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM iceberg.tpch.products\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5f48430-a379-42c6-94f7-5b0a33512a85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-------------------+-------------------+-------------------+\n",
      "|made_current_at        |snapshot_id        |parent_id          |is_current_ancestor|\n",
      "+-----------------------+-------------------+-------------------+-------------------+\n",
      "|2025-02-02 19:13:01.589|5030089142580687202|NULL               |true               |\n",
      "|2025-02-02 19:13:39.836|3249960666204203601|5030089142580687202|true               |\n",
      "|2025-02-02 19:14:55.659|6327152097578355969|3249960666204203601|true               |\n",
      "+-----------------------+-------------------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# history\n",
    "spark.sql(\"SELECT * FROM iceberg.tpch.products.history\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9374da8-0d32-4491-a7d7-f37a61bf1369",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------------------+\n",
      "|snapshot_id        |committed_at           |\n",
      "+-------------------+-----------------------+\n",
      "|5030089142580687202|2025-02-02 19:13:01.589|\n",
      "|3249960666204203601|2025-02-02 19:13:39.836|\n",
      "|6327152097578355969|2025-02-02 19:14:55.659|\n",
      "+-------------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Time Travel Using VERSION AS OF snapshot_id\n",
    "spark.sql(\"SELECT snapshot_id, committed_at FROM iceberg.tpch.products.snapshots\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd85911f-d6f2-4499-b912-455dea904db0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+-------+\n",
      "|product_id|  name|  price|\n",
      "+----------+------+-------+\n",
      "|         1|Laptop|1099.99|\n",
      "|         2| Phone| 499.99|\n",
      "+----------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT * FROM iceberg.tpch.products \n",
    "VERSION AS OF 6327152097578355969\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ed96ad8-5418-41f7-9e4e-7a30692c10b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 24:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+------+\n",
      "|product_id|  name| price|\n",
      "+----------+------+------+\n",
      "|         1|Laptop|999.99|\n",
      "|         2| Phone|499.99|\n",
      "|         3|Tablet|299.99|\n",
      "+----------+------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# time travel using  TIMESTAMP AS OF\n",
    "# copy time stamp from above products.snapshots query\n",
    "spark.sql(\"\"\"\n",
    "SELECT * FROM iceberg.tpch.products \n",
    "TIMESTAMP AS OF TIMESTAMP '2025-02-02 19:13:01.589'\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ad12cf7-4456-46fc-b091-2ecaeee8b60e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-------------------+-------------------+---------+------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|committed_at           |snapshot_id        |parent_id          |operation|manifest_list                                                                                                                 |summary                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n",
      "+-----------------------+-------------------+-------------------+---------+------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|2025-02-02 19:13:01.589|5030089142580687202|NULL               |append   |gs://tpch-source/iceberg_warehouse/tpch/products/metadata/snap-5030089142580687202-1-49f9a01b-efa0-49f4-bda3-07f37d734b9e.avro|{spark.app.id -> application_1738523049244_0001, added-data-files -> 2, added-records -> 3, added-files-size -> 1839, changed-partition-count -> 1, total-records -> 3, total-files-size -> 1839, total-data-files -> 2, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0, engine-version -> 3.5.1, app-id -> application_1738523049244_0001, engine-name -> spark, iceberg-version -> Apache Iceberg 1.7.1 (commit 4a432839233f2343a9eae8255532f911f06358ef)}                                                                         |\n",
      "|2025-02-02 19:13:39.836|3249960666204203601|5030089142580687202|overwrite|gs://tpch-source/iceberg_warehouse/tpch/products/metadata/snap-3249960666204203601-1-ae9fb662-5d56-486a-a83b-a038ad52dd91.avro|{spark.app.id -> application_1738523049244_0001, added-data-files -> 1, deleted-data-files -> 1, added-records -> 1, deleted-records -> 1, added-files-size -> 952, removed-files-size -> 928, changed-partition-count -> 1, total-records -> 3, total-files-size -> 1863, total-data-files -> 2, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0, engine-version -> 3.5.1, app-id -> application_1738523049244_0001, engine-name -> spark, iceberg-version -> Apache Iceberg 1.7.1 (commit 4a432839233f2343a9eae8255532f911f06358ef)}|\n",
      "|2025-02-02 19:14:55.659|6327152097578355969|3249960666204203601|overwrite|gs://tpch-source/iceberg_warehouse/tpch/products/metadata/snap-6327152097578355969-1-3c5efb14-b102-40f7-a6ef-3b89bd457a09.avro|{spark.app.id -> application_1738523049244_0001, added-data-files -> 1, deleted-data-files -> 1, added-records -> 1, deleted-records -> 2, added-files-size -> 945, removed-files-size -> 911, changed-partition-count -> 1, total-records -> 2, total-files-size -> 1897, total-data-files -> 2, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0, engine-version -> 3.5.1, app-id -> application_1738523049244_0001, engine-name -> spark, iceberg-version -> Apache Iceberg 1.7.1 (commit 4a432839233f2343a9eae8255532f911f06358ef)}|\n",
      "+-----------------------+-------------------+-------------------+---------+------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM iceberg.tpch.products.snapshots\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9dc73360-bed1-41cd-bbfd-e22802078f18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-------------------+-------------------+-------------------+\n",
      "|made_current_at        |snapshot_id        |parent_id          |is_current_ancestor|\n",
      "+-----------------------+-------------------+-------------------+-------------------+\n",
      "|2025-02-02 19:13:01.589|5030089142580687202|NULL               |true               |\n",
      "|2025-02-02 19:13:39.836|3249960666204203601|5030089142580687202|true               |\n",
      "|2025-02-02 19:14:55.659|6327152097578355969|3249960666204203601|true               |\n",
      "+-----------------------+-------------------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM iceberg.tpch.products.history\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99e7cfd0-ad10-4099-96e0-97b36ff86256",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+-------+\n",
      "|product_id|name  |price  |\n",
      "+----------+------+-------+\n",
      "|1         |Laptop|1099.99|\n",
      "|2         |Phone |499.99 |\n",
      "+----------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM iceberg.tpch.products\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5dbeefa1-9575-4948-8801-4bc6683e930c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------------------+\n",
      "|snapshot_id        |committed_at           |\n",
      "+-------------------+-----------------------+\n",
      "|5030089142580687202|2025-02-02 19:13:01.589|\n",
      "|3249960666204203601|2025-02-02 19:13:39.836|\n",
      "|6327152097578355969|2025-02-02 19:14:55.659|\n",
      "+-------------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT snapshot_id, committed_at FROM iceberg.tpch.products.snapshots\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab67d3e1-57c9-47df-8292-78d521807cda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+-------+\n",
      "|product_id|  name|  price|\n",
      "+----------+------+-------+\n",
      "|         2| Phone| 499.99|\n",
      "|         1|Laptop|1099.99|\n",
      "+----------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_old = spark.read.format(\"iceberg\").option(\"snapshot-id\", 6327152097578355969).load(\"iceberg.tpch.products\")\n",
    "df_old.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0f7b4c-5574-44cd-91ae-da53aa6aa12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overwrite data from rollback\n",
    "\n",
    "df_old.write.format(\"iceberg\").mode(\"overwrite\").save(\"iceberg.tpch.products\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d491e8bf-319e-4ef6-8bf5-0e05214b4629",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ParseException",
     "evalue": "\n[PARSE_SYNTAX_ERROR] Syntax error at or near 'CALL'.(line 1, pos 0)\n\n== SQL ==\nCALL iceberg.tpch.system.rollback_to_snapshot('tpch.products', 6327152097578355969)\n^^^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParseException\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCALL iceberg.tpch.system.rollback_to_snapshot(\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtpch.products\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m, 6327152097578355969)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/spark/python/pyspark/sql/session.py:1631\u001b[0m, in \u001b[0;36mSparkSession.sql\u001b[0;34m(self, sqlQuery, args, **kwargs)\u001b[0m\n\u001b[1;32m   1627\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1628\u001b[0m         litArgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonUtils\u001b[38;5;241m.\u001b[39mtoArray(\n\u001b[1;32m   1629\u001b[0m             [_to_java_column(lit(v)) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m (args \u001b[38;5;129;01mor\u001b[39;00m [])]\n\u001b[1;32m   1630\u001b[0m         )\n\u001b[0;32m-> 1631\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqlQuery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlitArgs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1632\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1633\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/lib/spark/python/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mParseException\u001b[0m: \n[PARSE_SYNTAX_ERROR] Syntax error at or near 'CALL'.(line 1, pos 0)\n\n== SQL ==\nCALL iceberg.tpch.system.rollback_to_snapshot('tpch.products', 6327152097578355969)\n^^^\n"
     ]
    }
   ],
   "source": [
    "# will not work due to extentions not enabled\n",
    "spark.sql(\"CALL iceberg.tpch.system.rollback_to_snapshot('tpch.products', 6327152097578355969)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "345c9a91-7f0c-4a49-9a25-1607e47bedf2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Cannot modify the value of a static config: spark.sql.extensions.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspark.sql.extensions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43morg.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/spark/python/pyspark/sql/conf.py:43\u001b[0m, in \u001b[0;36mRuntimeConfig.set\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;129m@since\u001b[39m(\u001b[38;5;241m2.0\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mset\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mstr\u001b[39m, value: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mbool\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Sets the given Spark runtime configuration property.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jconf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/lib/spark/python/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Cannot modify the value of a static config: spark.sql.extensions."
     ]
    }
   ],
   "source": [
    "# must be set at begining.\n",
    "spark.conf.set(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fbce1a79-25f2-4192-a5e1-883e7415e3df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.stop() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}