{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daf4925a-2212-4bc5-86b5-7a792991a667",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/02/06 12:15:11 INFO SparkEnv: Registering MapOutputTracker\n",
      "25/02/06 12:15:11 INFO SparkEnv: Registering BlockManagerMaster\n",
      "25/02/06 12:15:11 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "25/02/06 12:15:11 INFO SparkEnv: Registering OutputCommitCoordinator\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, window, count, avg, sum, to_date, to_timestamp\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Streaming Aggregation\") \\\n",
    "    .master(\"yarn\") \\\n",
    "    .config(\"spark.submit.deployMode\", \"client\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"4\") \\\n",
    "    .config(\"spark.sql.catalog.iceberg\", \"org.apache.iceberg.spark.SparkCatalog\")\\\n",
    "    .config(\"spark.sql.catalog.iceberg.type\", \"hadoop\")\\\n",
    "    .config(\"spark.sql.catalog.iceberg.warehouse\", \"gs://gks-tpch/iceberg_warehouse\")\\\n",
    "    .getOrCreate()\n",
    " \n",
    "# Input path where streaming files arrive\n",
    "streaming_path = \"gs://tpch-source/orders-partittions2/\"\n",
    "output_path = \"gs://tpch-source/orders-aggregates/\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cfe8654-c032-446b-bc9d-4ed96d539f0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- o_orderkey: integer (nullable = true)\n",
      " |-- o_custkey: integer (nullable = true)\n",
      " |-- o_orderstatus: string (nullable = true)\n",
      " |-- o_totalprice: double (nullable = true)\n",
      " |-- o_orderdate: string (nullable = true)\n",
      " |-- o_orderpriority: string (nullable = true)\n",
      " |-- o_clerk: string (nullable = true)\n",
      " |-- o_shippriority: integer (nullable = true)\n",
      " |-- o_comment: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define Schema for Orders\n",
    "schema = \"\"\"\n",
    "    o_orderkey INT,\n",
    "    o_custkey INT,\n",
    "    o_orderstatus STRING,\n",
    "    o_totalprice DOUBLE,\n",
    "    o_orderdate STRING,\n",
    "    o_orderpriority STRING,\n",
    "    o_clerk STRING,\n",
    "    o_shippriority INT,\n",
    "    o_comment STRING\n",
    "\"\"\"\n",
    "\n",
    "# Read Streaming Data\n",
    "df_stream = spark.readStream \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(schema) \\\n",
    "    .csv(streaming_path)\n",
    "\n",
    "df_stream.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86d3dbf2-0149-443c-b103-71c38e71e381",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- o_orderkey: integer (nullable = true)\n",
      " |-- o_custkey: integer (nullable = true)\n",
      " |-- o_orderstatus: string (nullable = true)\n",
      " |-- o_totalprice: double (nullable = true)\n",
      " |-- o_orderdate: timestamp (nullable = true)\n",
      " |-- o_orderpriority: string (nullable = true)\n",
      " |-- o_clerk: string (nullable = true)\n",
      " |-- o_shippriority: integer (nullable = true)\n",
      " |-- o_comment: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert order date to proper Date format\n",
    "# df_stream = df_stream.withColumn(\"o_orderdate\", to_date(col(\"o_orderdate\")))\n",
    "df_stream = df_stream.withColumn(\"o_orderdate\", to_timestamp(col(\"o_orderdate\"), \"yyyy-MM-dd\"))\n",
    "\n",
    "df_stream.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64b22924-f0b2-40a7-af54-c7497f76e294",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- month_start: timestamp (nullable = true)\n",
      " |-- month_end: timestamp (nullable = true)\n",
      " |-- o_custkey: integer (nullable = true)\n",
      " |-- total_orders: long (nullable = false)\n",
      " |-- avg_totalprice: double (nullable = true)\n",
      " |-- sum_totalprice: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#     .withWatermark(\"o_orderdate\", \"2 months\") \\\n",
    "\n",
    "# Aggregate by Month & Customer Key\n",
    "aggregated_df = df_stream \\\n",
    "    .groupBy(window(col(\"o_orderdate\"), \"7 days\"), col(\"o_custkey\")) \\\n",
    "    .agg(\n",
    "        count(\"o_orderkey\").alias(\"total_orders\"),\n",
    "        avg(\"o_totalprice\").alias(\"avg_totalprice\"),\n",
    "        sum(\"o_totalprice\").alias(\"sum_totalprice\")\n",
    "    ) \\\n",
    "    .select(\n",
    "        col(\"window.start\").alias(\"month_start\"),\n",
    "        col(\"window.end\").alias(\"month_end\"),\n",
    "        col(\"o_custkey\"),\n",
    "        col(\"total_orders\"),\n",
    "        col(\"avg_totalprice\"),\n",
    "        col(\"sum_totalprice\")\n",
    "    )\n",
    "\n",
    "aggregated_df.printSchema()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f6cc69d6-4f3a-44cc-a9cb-31e614ac97da",
   "metadata": {},
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE TABLE iceberg.tpch.aggregated_orders (\n",
    "    week_start TIMESTAMP,\n",
    "    week_end TIMESTAMP,\n",
    "    o_custkey INT,\n",
    "    total_orders INT,\n",
    "    avg_totalprice DOUBLE,\n",
    "    sum_totalprice DOUBLE\n",
    ") USING iceberg\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc63357d-7780-4082-99a9-c4cda24aee0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/06 12:21:39 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.query.StreamingQuery at 0x7fd78b12b150>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/06 12:21:48 WARN FileStreamSource: Listed 185 file(s) in 5496 ms          \n",
      "25/02/06 12:25:06 WARN FileStreamSource: Listed 224 file(s) in 6205 ms          \n",
      "25/02/06 12:30:08 WARN FileStreamSource: Listed 284 file(s) in 8234 ms          \n",
      "25/02/06 12:35:09 WARN FileStreamSource: Listed 343 file(s) in 9538 ms          \n",
      "25/02/06 12:40:10 WARN FileStreamSource: Listed 403 file(s) in 10886 ms         \n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "# Write Streaming Aggregated Results to GCS\n",
    "aggregated_df.writeStream \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .option(\"checkpointLocation\", \"gs://tpch-source/checkpoints/gks-aggregated_orders/\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .format(\"iceberg\") \\\n",
    "    .trigger(processingTime=\"5 minutes\") \\\n",
    "    .toTable(\"iceberg.tpch.aggregated_orders\")\n",
    "    # .start(output_path) \\\n",
    "    # .awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddf1e47-37a3-4650-8d2b-117891be9553",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}