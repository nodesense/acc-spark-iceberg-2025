{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbe3e7b1-61d5-4e5a-a0c0-02bdc726b029",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Take data from silver zone (clean zone) and apply aggregate, move to gold zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfbd9dba-2516-4c18-96ec-0ec209a1f15c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/06 05:59:10 INFO SparkEnv: Registering MapOutputTracker\n",
      "25/02/06 05:59:10 INFO SparkEnv: Registering BlockManagerMaster\n",
      "25/02/06 05:59:10 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "25/02/06 05:59:10 INFO SparkEnv: Registering OutputCommitCoordinator\n"
     ]
    }
   ],
   "source": [
    "# spark session is not initialized\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "# in general, you dont hardcode the config in code, instead we will use spark-submit\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"GKSMovieRatingAggregate\") \\\n",
    "    .master(\"yarn\") \\\n",
    "    .config(\"spark.submit.deployMode\", \"client\") \\\n",
    "    .config(\"spark.executor.instances\", \"1\") \\\n",
    "    .config(\"spark.executor.cores\", \"2\") \\\n",
    "    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "186a46a1-8fb0-4eb0-8fd1-ce3f191711a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.catalog.iceberg\", \"org.apache.iceberg.spark.SparkCatalog\")\n",
    "spark.conf.set(\"spark.sql.catalog.iceberg.type\", \"hadoop\")\n",
    "spark.conf.set(\"spark.sql.catalog.iceberg.warehouse\", \"gs://gks-tpch/iceberg_warehouse\") # FIX the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92160c5e-7676-4f67-9553-8810399532c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+--------------------+\n",
      "|movieId|           title|              genres|\n",
      "+-------+----------------+--------------------+\n",
      "|      1|Toy Story (1995)|Adventure|Animati...|\n",
      "|      2|  Jumanji (1995)|Adventure|Childre...|\n",
      "+-------+----------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "movieDf = spark.sql(\"SELECT * FROM iceberg.movielens.movies\")\n",
    "movieDf.printSchema()\n",
    "movieDf.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2370889-8775-4c78-9244-512dd0ce6625",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: long (nullable = true)\n",
      "\n",
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|     1|      1|   4.0|964982703|\n",
      "|     1|      3|   4.0|964981247|\n",
      "+------+-------+------+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "ratingDf = spark.table(\"iceberg.movielens.ratings\")\n",
    "ratingDf.printSchema()\n",
    "ratingDf.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "020b0c39-1b76-4de2-a40e-9912e6affc9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- avg_rating: double (nullable = true)\n",
      " |-- total_ratings: long (nullable = false)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------------+\n",
      "|movieId|        avg_rating|total_ratings|\n",
      "+-------+------------------+-------------+\n",
      "|    356| 4.175304878048781|          328|\n",
      "|    318| 4.429022082018927|          317|\n",
      "|    296| 4.221311475409836|          305|\n",
      "|    593| 4.201086956521739|          276|\n",
      "|   2571|  4.26007326007326|          273|\n",
      "|    260|             4.246|          250|\n",
      "|    480|3.7637130801687766|          237|\n",
      "|    110| 4.046610169491525|          236|\n",
      "|    589| 4.018099547511312|          221|\n",
      "|    527| 4.259174311926605|          218|\n",
      "|   2959| 4.325581395348837|          215|\n",
      "|      1|3.9369158878504673|          214|\n",
      "|   1196| 4.233333333333333|          210|\n",
      "|     50| 4.237745098039215|          204|\n",
      "|   2858| 4.073891625615763|          203|\n",
      "|    150| 3.845771144278607|          201|\n",
      "|     47| 4.009950248756219|          201|\n",
      "|   1198| 4.226130653266332|          199|\n",
      "|   4993| 4.142857142857143|          196|\n",
      "|   1210| 4.137755102040816|          196|\n",
      "+-------+------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# aggregation with groupBy\n",
    "from pyspark.sql.functions import col, desc, avg, count\n",
    "\n",
    "# find  the most popular movies, where as rated by many users, at least movies should be rated by 100 users\n",
    "# and the average rating should be at least 3.5 and above\n",
    "# and sort the movies by total_ratings\n",
    "mostPopularMoviesDf = ratingDf\\\n",
    "     .groupBy(\"movieId\")\\\n",
    "     .agg(avg(\"rating\").alias(\"avg_rating\"), count(\"userId\").alias(\"total_ratings\") )\\\n",
    "     .sort(desc(\"total_ratings\"))\\\n",
    "     .filter( (col(\"total_ratings\") >= 100) & (col(\"avg_rating\") >=3.5) )\n",
    "    \n",
    "# mostPopularMoviesDf.cache() # MEMORY\n",
    "\n",
    "mostPopularMoviesDf.printSchema()\n",
    "mostPopularMoviesDf.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91f9dd6f-b4fd-4b36-b970-c018a3aebcae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Sort [total_ratings#155L DESC NULLS LAST], true, 0\n",
      "   +- Exchange rangepartitioning(total_ratings#155L DESC NULLS LAST, 1000), ENSURE_REQUIREMENTS, [plan_id=175]\n",
      "      +- Filter (isnotnull(avg_rating#153) AND ((total_ratings#155L >= 100) AND (avg_rating#153 >= 3.5)))\n",
      "         +- HashAggregate(keys=[movieId#115], functions=[avg(rating#116), count(userId#114)])\n",
      "            +- Exchange hashpartitioning(movieId#115, 1000), ENSURE_REQUIREMENTS, [plan_id=171]\n",
      "               +- HashAggregate(keys=[movieId#115], functions=[partial_avg(rating#116), partial_count(userId#114)])\n",
      "                  +- BatchScan iceberg.movielens.ratings[userId#114, movieId#115, rating#116] iceberg.movielens.ratings (branch=null) [filters=, groupedBy=] RuntimeFilters: []\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mostPopularMoviesDf.explain() # print physical plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "68818058-adc3-489e-a5dd-46e853ac8101",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Filter (('total_ratings >= 100) AND ('avg_rating >= 3.5))\n",
      "+- Sort [total_ratings#201L DESC NULLS LAST], true\n",
      "   +- Aggregate [movieId#115], [movieId#115, avg(rating#116) AS avg_rating#199, count(userId#114) AS total_ratings#201L]\n",
      "      +- SubqueryAlias iceberg.movielens.ratings\n",
      "         +- RelationV2[userId#114, movieId#115, rating#116, timestamp#117L] iceberg.movielens.ratings iceberg.movielens.ratings\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "movieId: int, avg_rating: double, total_ratings: bigint\n",
      "Filter ((total_ratings#201L >= cast(100 as bigint)) AND (avg_rating#199 >= 3.5))\n",
      "+- Sort [total_ratings#201L DESC NULLS LAST], true\n",
      "   +- Aggregate [movieId#115], [movieId#115, avg(rating#116) AS avg_rating#199, count(userId#114) AS total_ratings#201L]\n",
      "      +- SubqueryAlias iceberg.movielens.ratings\n",
      "         +- RelationV2[userId#114, movieId#115, rating#116, timestamp#117L] iceberg.movielens.ratings iceberg.movielens.ratings\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Sort [total_ratings#201L DESC NULLS LAST], true\n",
      "+- Filter (isnotnull(avg_rating#199) AND ((total_ratings#201L >= 100) AND (avg_rating#199 >= 3.5)))\n",
      "   +- Aggregate [movieId#115], [movieId#115, avg(rating#116) AS avg_rating#199, count(userId#114) AS total_ratings#201L]\n",
      "      +- RelationV2[userId#114, movieId#115, rating#116] iceberg.movielens.ratings\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Sort [total_ratings#201L DESC NULLS LAST], true, 0\n",
      "   +- Exchange rangepartitioning(total_ratings#201L DESC NULLS LAST, 1000), ENSURE_REQUIREMENTS, [plan_id=259]\n",
      "      +- Filter (isnotnull(avg_rating#199) AND ((total_ratings#201L >= 100) AND (avg_rating#199 >= 3.5)))\n",
      "         +- HashAggregate(keys=[movieId#115], functions=[avg(rating#116), count(userId#114)], output=[movieId#115, avg_rating#199, total_ratings#201L])\n",
      "            +- Exchange hashpartitioning(movieId#115, 1000), ENSURE_REQUIREMENTS, [plan_id=255]\n",
      "               +- HashAggregate(keys=[movieId#115], functions=[partial_avg(rating#116), partial_count(userId#114)], output=[movieId#115, sum#222, count#223L, count#224L])\n",
      "                  +- BatchScan iceberg.movielens.ratings[userId#114, movieId#115, rating#116] iceberg.movielens.ratings (branch=null) [filters=, groupedBy=] RuntimeFilters: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mostPopularMoviesDf.explain(extended = True) # print parsed logical plan, analysed locical plan, optimized logical plan, physical plan\n",
    "\n",
    "# parsed logical plan - the code logic as we wrote.. not optimized, no schema/datatypes applied\n",
    "# execution shall be from bottom up, bottom statement exuected first\n",
    "# movieId#115, 115 is a internal spark reference for a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8689813b-67a3-4edf-9b94-8a660d8e1f60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------------------+-------------+\n",
      "|movieId|               title|        avg_rating|total_ratings|\n",
      "+-------+--------------------+------------------+-------------+\n",
      "|    356| Forrest Gump (1994)| 4.175304878048781|          328|\n",
      "|    318|Shawshank Redempt...| 4.429022082018927|          317|\n",
      "|    296| Pulp Fiction (1994)| 4.221311475409836|          305|\n",
      "|    593|Silence of the La...| 4.201086956521739|          276|\n",
      "|   2571|  Matrix, The (1999)|  4.26007326007326|          273|\n",
      "|    260|Star Wars: Episod...|             4.246|          250|\n",
      "|    480|Jurassic Park (1993)|3.7637130801687766|          237|\n",
      "|    110|   Braveheart (1995)| 4.046610169491525|          236|\n",
      "|    589|Terminator 2: Jud...| 4.018099547511312|          221|\n",
      "|    527|Schindler's List ...| 4.259174311926605|          218|\n",
      "|   2959|   Fight Club (1999)| 4.325581395348837|          215|\n",
      "|      1|    Toy Story (1995)|3.9369158878504673|          214|\n",
      "|   1196|Star Wars: Episod...| 4.233333333333333|          210|\n",
      "|     50|Usual Suspects, T...| 4.237745098039215|          204|\n",
      "|   2858|American Beauty (...| 4.073891625615763|          203|\n",
      "|     47|Seven (a.k.a. Se7...| 4.009950248756219|          201|\n",
      "|    150|    Apollo 13 (1995)| 3.845771144278607|          201|\n",
      "|   1198|Raiders of the Lo...| 4.226130653266332|          199|\n",
      "|   4993|Lord of the Rings...| 4.142857142857143|          196|\n",
      "|   1210|Star Wars: Episod...| 4.137755102040816|          196|\n",
      "|    858|Godfather, The (1...|         4.2890625|          192|\n",
      "|    457|Fugitive, The (1993)|  4.01058201058201|          189|\n",
      "|   2028|Saving Private Ry...| 4.165775401069519|          187|\n",
      "|   5952|Lord of the Rings...| 4.040106951871658|          187|\n",
      "|   7153|Lord of the Rings...| 4.118918918918919|          185|\n",
      "|    588|      Aladdin (1992)|3.8104395604395602|          182|\n",
      "|    608|        Fargo (1996)| 4.116022099447513|          181|\n",
      "|    380|    True Lies (1994)|3.5141242937853105|          177|\n",
      "|     32|Twelve Monkeys (a...| 3.983050847457627|          177|\n",
      "|   2762|Sixth Sense, The ...|3.9517045454545454|          176|\n",
      "|    364|Lion King, The (1...| 3.941860465116279|          172|\n",
      "|   1270|Back to the Futur...| 4.038011695906433|          171|\n",
      "|    377|        Speed (1994)|3.5470588235294116|          170|\n",
      "|   4306|        Shrek (2001)|3.8875739644970415|          169|\n",
      "|   3578|    Gladiator (2000)|3.9791666666666665|          168|\n",
      "|    590|Dances with Wolve...|3.8353658536585367|          164|\n",
      "|   1580|Men in Black (a.k...|3.5245398773006134|          163|\n",
      "|    648|Mission: Impossib...|3.5559006211180124|          161|\n",
      "|   4226|      Memento (2000)|4.1455696202531644|          158|\n",
      "|  58559|Dark Knight, The ...| 4.238255033557047|          149|\n",
      "|   6539|Pirates of the Ca...| 3.800675675675676|          148|\n",
      "|    595|Beauty and the Be...|3.7705479452054793|          146|\n",
      "|   1214|        Alien (1979)|3.9931034482758623|          145|\n",
      "|   1036|     Die Hard (1988)|3.8854166666666665|          144|\n",
      "|    165|Die Hard: With a ...|3.5555555555555554|          144|\n",
      "|   1265|Groundhog Day (1993)| 3.944055944055944|          143|\n",
      "|   1197|Princess Bride, T...| 4.232394366197183|          142|\n",
      "|  79132|    Inception (2010)| 4.091549295774648|          142|\n",
      "|   1704|Good Will Hunting...| 4.078014184397163|          141|\n",
      "|   6377| Finding Nemo (2003)|3.9857142857142858|          140|\n",
      "|   1291|Indiana Jones and...| 4.071942446043166|          139|\n",
      "|   1136|Monty Python and ...| 4.188888888888889|          135|\n",
      "|    597| Pretty Woman (1990)|3.5074626865671643|          134|\n",
      "|    293|LÃ©on: The Profess...| 4.018796992481203|          133|\n",
      "|   1193|One Flew Over the...| 4.203007518796992|          133|\n",
      "|   1089|Reservoir Dogs (1...| 4.202290076335878|          131|\n",
      "|   4886|Monsters, Inc. (2...|3.8969465648854964|          131|\n",
      "|   3793|        X-Men (2000)|3.7480916030534353|          131|\n",
      "|     10|    GoldenEye (1995)| 3.519083969465649|          131|\n",
      "|   7361|Eternal Sunshine ...| 4.188461538461539|          130|\n",
      "|   2329|American History ...| 4.217054263565892|          129|\n",
      "|   1240|Terminator, The (...| 3.949612403100775|          129|\n",
      "|   1221|Godfather: Part I...|  4.25968992248062|          129|\n",
      "|   6874|Kill Bill: Vol. 1...| 4.015503875968992|          129|\n",
      "|     34|         Babe (1995)|        3.65234375|          128|\n",
      "|   1213|   Goodfellas (1990)|              4.25|          126|\n",
      "|   1200|       Aliens (1986)|3.9642857142857144|          126|\n",
      "|   8961|Incredibles, The ...|3.8629032258064515|          124|\n",
      "|   1682|Truman Show, The ...| 3.838709677419355|          124|\n",
      "|    541| Blade Runner (1982)| 4.130081300813008|          123|\n",
      "|   4995|Beautiful Mind, A...| 4.028688524590164|          122|\n",
      "|   1097|E.T. the Extra-Te...|3.8208333333333333|          120|\n",
      "|    733|    Rock, The (1996)|3.6666666666666665|          120|\n",
      "|   2716|Ghostbusters (a.k...|             3.775|          120|\n",
      "|   5349|   Spider-Man (2002)|3.6176470588235294|          119|\n",
      "|   4973|Amelie (Fabuleux ...| 4.214285714285714|          119|\n",
      "|   1206|Clockwork Orange,...| 4.055084745762712|          118|\n",
      "|   4963|Ocean's Eleven (2...|3.8728813559322033|          118|\n",
      "|   5445|Minority Report (...| 3.690677966101695|          118|\n",
      "|   1073|Willy Wonka & the...|3.9316239316239314|          117|\n",
      "|  33794|Batman Begins (2005)|3.8620689655172415|          116|\n",
      "|   1527|Fifth Element, Th...|3.7456896551724137|          116|\n",
      "|   5989|Catch Me If You C...|3.9217391304347826|          115|\n",
      "|   1968|Breakfast Club, T...|3.7787610619469025|          113|\n",
      "|   3147|Green Mile, The (...| 4.181818181818182|          110|\n",
      "|    349|Clear and Present...|3.6045454545454545|          110|\n",
      "|   5418|Bourne Identity, ...|3.8772727272727274|          110|\n",
      "|    924|2001: A Space Ody...|3.8944954128440368|          109|\n",
      "|   2918|Ferris Bueller's ...|3.8394495412844036|          109|\n",
      "|   7438|Kill Bill: Vol. 2...|3.8990825688073394|          109|\n",
      "|   1258| Shining, The (1980)|  4.08256880733945|          109|\n",
      "|   2115|Indiana Jones and...| 3.638888888888889|          108|\n",
      "|   4878| Donnie Darko (2001)| 4.013888888888889|          108|\n",
      "|   1208|Apocalypse Now (1...| 4.219626168224299|          107|\n",
      "|    253|Interview with th...| 3.514018691588785|          107|\n",
      "|  48516|Departed, The (2006)| 4.252336448598131|          107|\n",
      "|   4896|Harry Potter and ...|3.7616822429906542|          107|\n",
      "|   3996|Crouching Tiger, ...|3.9299065420560746|          107|\n",
      "|   1923|There's Something...| 3.676190476190476|          105|\n",
      "|  68954|           Up (2009)| 4.038461538461538|          104|\n",
      "+-------+--------------------+------------------+-------------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# join, inner join \n",
    "# get the movie title for the mostPopularMoviesDf\n",
    "# join mostPopularMoviesDf with movieDf based on condition that mostPopularMoviesDf.movieId == movieDf.movieId\n",
    "\n",
    "# left as big table, fact/transactional data, huge data\n",
    "# right as small table, dimention data, small data set\n",
    "\n",
    "# based on runtime, at the time of physical plans, spark will see how many movies, how much executor memory present\n",
    "# based on that, it decide normal shuffle join (time consumng,expensive) or broadCast join\n",
    "popularMoviesDf = mostPopularMoviesDf.join(movieDf, mostPopularMoviesDf.movieId == movieDf.movieId)\\\n",
    "                                     .select(movieDf.movieId, \"title\", \"avg_rating\", \"total_ratings\")\\\n",
    "                                     .sort(desc(\"total_ratings\"))\n",
    "\n",
    "# popularMoviesDf.cache()\n",
    "\n",
    "popularMoviesDf.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "76990313-d284-42cd-b8c2-d60724c1df46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Sort ['total_ratings DESC NULLS LAST], true\n",
      "+- Project [movieId#87, title#88, avg_rating#199, total_ratings#201L]\n",
      "   +- Join Inner, (movieId#115 = movieId#87)\n",
      "      :- Filter ((total_ratings#201L >= cast(100 as bigint)) AND (avg_rating#199 >= 3.5))\n",
      "      :  +- Sort [total_ratings#201L DESC NULLS LAST], true\n",
      "      :     +- Aggregate [movieId#115], [movieId#115, avg(rating#116) AS avg_rating#199, count(userId#114) AS total_ratings#201L]\n",
      "      :        +- SubqueryAlias iceberg.movielens.ratings\n",
      "      :           +- RelationV2[userId#114, movieId#115, rating#116, timestamp#117L] iceberg.movielens.ratings iceberg.movielens.ratings\n",
      "      +- Project [movieId#87, title#88, genres#89]\n",
      "         +- SubqueryAlias iceberg.movielens.movies\n",
      "            +- RelationV2[movieId#87, title#88, genres#89] iceberg.movielens.movies iceberg.movielens.movies\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "movieId: int, title: string, avg_rating: double, total_ratings: bigint\n",
      "Sort [total_ratings#201L DESC NULLS LAST], true\n",
      "+- Project [movieId#87, title#88, avg_rating#199, total_ratings#201L]\n",
      "   +- Join Inner, (movieId#115 = movieId#87)\n",
      "      :- Filter ((total_ratings#201L >= cast(100 as bigint)) AND (avg_rating#199 >= 3.5))\n",
      "      :  +- Sort [total_ratings#201L DESC NULLS LAST], true\n",
      "      :     +- Aggregate [movieId#115], [movieId#115, avg(rating#116) AS avg_rating#199, count(userId#114) AS total_ratings#201L]\n",
      "      :        +- SubqueryAlias iceberg.movielens.ratings\n",
      "      :           +- RelationV2[userId#114, movieId#115, rating#116, timestamp#117L] iceberg.movielens.ratings iceberg.movielens.ratings\n",
      "      +- Project [movieId#87, title#88, genres#89]\n",
      "         +- SubqueryAlias iceberg.movielens.movies\n",
      "            +- RelationV2[movieId#87, title#88, genres#89] iceberg.movielens.movies iceberg.movielens.movies\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Sort [total_ratings#201L DESC NULLS LAST], true\n",
      "+- Project [movieId#87, title#88, avg_rating#199, total_ratings#201L]\n",
      "   +- Join Inner, (movieId#115 = movieId#87)\n",
      "      :- Filter ((isnotnull(avg_rating#199) AND (total_ratings#201L >= 100)) AND (avg_rating#199 >= 3.5))\n",
      "      :  +- Aggregate [movieId#115], [movieId#115, avg(rating#116) AS avg_rating#199, count(userId#114) AS total_ratings#201L]\n",
      "      :     +- Filter isnotnull(movieId#115)\n",
      "      :        +- RelationV2[userId#114, movieId#115, rating#116] iceberg.movielens.ratings\n",
      "      +- Filter isnotnull(movieId#87)\n",
      "         +- RelationV2[movieId#87, title#88] iceberg.movielens.movies\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Sort [total_ratings#201L DESC NULLS LAST], true, 0\n",
      "   +- Exchange rangepartitioning(total_ratings#201L DESC NULLS LAST, 1000), ENSURE_REQUIREMENTS, [plan_id=455]\n",
      "      +- Project [movieId#87, title#88, avg_rating#199, total_ratings#201L]\n",
      "         +- BroadcastHashJoin [movieId#115], [movieId#87], Inner, BuildRight, false\n",
      "            :- Filter ((isnotnull(avg_rating#199) AND (total_ratings#201L >= 100)) AND (avg_rating#199 >= 3.5))\n",
      "            :  +- HashAggregate(keys=[movieId#115], functions=[avg(rating#116), count(userId#114)], output=[movieId#115, avg_rating#199, total_ratings#201L])\n",
      "            :     +- Exchange hashpartitioning(movieId#115, 1000), ENSURE_REQUIREMENTS, [plan_id=447]\n",
      "            :        +- HashAggregate(keys=[movieId#115], functions=[partial_avg(rating#116), partial_count(userId#114)], output=[movieId#115, sum#222, count#223L, count#224L])\n",
      "            :           +- Filter isnotnull(movieId#115)\n",
      "            :              +- BatchScan iceberg.movielens.ratings[userId#114, movieId#115, rating#116] iceberg.movielens.ratings (branch=null) [filters=movieId IS NOT NULL, groupedBy=] RuntimeFilters: []\n",
      "            +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=451]\n",
      "               +- Filter isnotnull(movieId#87)\n",
      "                  +- BatchScan iceberg.movielens.movies[movieId#87, title#88] iceberg.movielens.movies (branch=null) [filters=movieId IS NOT NULL, groupedBy=] RuntimeFilters: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "popularMoviesDf.explain(extended = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b939ed6f-ca4c-4805-a3f3-6e27a464bf6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/06 06:56:53 WARN HadoopTableOperations: Error reading version hint file gs://gks-tpch/iceberg_warehouse/movielens/popular_movies1/metadata/version-hint.text\n",
      "java.io.FileNotFoundException: Item not found: 'gs://gks-tpch/iceberg_warehouse/movielens/popular_movies1/metadata/version-hint.text'. Note, it is possible that the live version is still available but the requested generation is deleted.\n",
      "\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageExceptions.createFileNotFoundException(GoogleCloudStorageExceptions.java:47) ~[gcs-connector-3.0.4.jar:?]\n",
      "\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.open(GoogleCloudStorageImpl.java:678) ~[gcs-connector-3.0.4.jar:?]\n",
      "\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.open(GoogleCloudStorageImpl.java:669) ~[gcs-connector-3.0.4.jar:?]\n",
      "\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageFileSystemImpl.open(GoogleCloudStorageFileSystemImpl.java:309) ~[gcs-connector-3.0.4.jar:?]\n",
      "\tat com.google.cloud.hadoop.fs.gcs.GoogleHadoopFSInputStream.create(GoogleHadoopFSInputStream.java:104) ~[gcs-connector-3.0.4.jar:?]\n",
      "\tat com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem.lambda$open$6(GoogleHadoopFileSystem.java:591) ~[gcs-connector-3.0.4.jar:?]\n",
      "\tat org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.invokeTrackingDuration(IOStatisticsBinding.java:547) ~[hadoop-client-api-3.3.6.jar:?]\n",
      "\tat org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.lambda$trackDurationOfOperation$5(IOStatisticsBinding.java:528) ~[hadoop-client-api-3.3.6.jar:?]\n",
      "\tat org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.trackDuration(IOStatisticsBinding.java:449) ~[hadoop-client-api-3.3.6.jar:?]\n",
      "\tat com.google.cloud.hadoop.fs.gcs.GhfsGlobalStorageStatistics.trackDuration(GhfsGlobalStorageStatistics.java:114) ~[gcs-connector-3.0.4.jar:?]\n",
      "\tat com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem.trackDurationWithTracing(GoogleHadoopFileSystem.java:759) ~[gcs-connector-3.0.4.jar:?]\n",
      "\tat com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem.open(GoogleHadoopFileSystem.java:579) ~[gcs-connector-3.0.4.jar:?]\n",
      "\tat org.apache.hadoop.fs.FileSystem.open(FileSystem.java:998) ~[hadoop-client-api-3.3.6.jar:?]\n",
      "\tat org.apache.iceberg.hadoop.HadoopTableOperations.findVersion(HadoopTableOperations.java:317) ~[iceberg-spark-runtime-3.5_2.12-1.7.1.jar:?]\n",
      "\tat org.apache.iceberg.hadoop.HadoopTableOperations.refresh(HadoopTableOperations.java:103) ~[iceberg-spark-runtime-3.5_2.12-1.7.1.jar:?]\n",
      "\tat org.apache.iceberg.BaseTransaction.lambda$commitReplaceTransaction$1(BaseTransaction.java:368) ~[iceberg-spark-runtime-3.5_2.12-1.7.1.jar:?]\n",
      "\tat org.apache.iceberg.util.Tasks$Builder.runTaskWithRetry(Tasks.java:413) ~[iceberg-spark-runtime-3.5_2.12-1.7.1.jar:?]\n",
      "\tat org.apache.iceberg.util.Tasks$Builder.runSingleThreaded(Tasks.java:219) ~[iceberg-spark-runtime-3.5_2.12-1.7.1.jar:?]\n",
      "\tat org.apache.iceberg.util.Tasks$Builder.run(Tasks.java:203) ~[iceberg-spark-runtime-3.5_2.12-1.7.1.jar:?]\n",
      "\tat org.apache.iceberg.util.Tasks$Builder.run(Tasks.java:196) ~[iceberg-spark-runtime-3.5_2.12-1.7.1.jar:?]\n",
      "\tat org.apache.iceberg.BaseTransaction.commitReplaceTransaction(BaseTransaction.java:365) ~[iceberg-spark-runtime-3.5_2.12-1.7.1.jar:?]\n",
      "\tat org.apache.iceberg.BaseTransaction.commitTransaction(BaseTransaction.java:314) ~[iceberg-spark-runtime-3.5_2.12-1.7.1.jar:?]\n",
      "\tat org.apache.iceberg.CommitCallbackTransaction.commitTransaction(CommitCallbackTransaction.java:126) ~[iceberg-spark-runtime-3.5_2.12-1.7.1.jar:?]\n",
      "\tat org.apache.iceberg.spark.source.StagedSparkTable.commitStagedChanges(StagedSparkTable.java:34) ~[iceberg-spark-runtime-3.5_2.12-1.7.1.jar:?]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CreateTableAsSelectBaseExec.$anonfun$writeToTable$1(WriteToDataSourceV2Exec.scala:599) ~[spark-sql_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1399) ~[spark-core_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CreateTableAsSelectBaseExec.writeToTable(WriteToDataSourceV2Exec.scala:592) ~[spark-sql_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CreateTableAsSelectBaseExec.writeToTable$(WriteToDataSourceV2Exec.scala:586) ~[spark-sql_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.AtomicReplaceTableAsSelectExec.writeToTable(WriteToDataSourceV2Exec.scala:185) ~[spark-sql_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.AtomicReplaceTableAsSelectExec.run(WriteToDataSourceV2Exec.scala:218) ~[spark-sql_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43) ~[spark-sql_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43) ~[spark-sql_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49) ~[spark-sql_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125) ~[spark-sql_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201) ~[spark-sql_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108) ~[spark-sql_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66) ~[spark-sql_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:473) ~[spark-catalyst_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76) [spark-sql-api_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:473) [spark-catalyst_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32) [spark-catalyst_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267) [spark-catalyst_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263) [spark-catalyst_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) [spark-catalyst_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) [spark-catalyst_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:449) [spark-catalyst_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98) [spark-sql_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85) [spark-sql_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83) [spark-sql_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142) [spark-sql_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859) [spark-sql_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:634) [spark-sql_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:564) [spark-sql_2.12-3.5.1.jar:3.5.1]\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:?]\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566) ~[?:?]\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106) [py4j-0.10.9.7.jar:?]\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "25/02/06 06:56:53 WARN HadoopTableOperations: Error reading version hint file gs://gks-tpch/iceberg_warehouse/movielens/popular_movies1/metadata/version-hint.text\n",
      "java.io.FileNotFoundException: Item not found: 'gs://gks-tpch/iceberg_warehouse/movielens/popular_movies1/metadata/version-hint.text'. Note, it is possible that the live version is still available but the requested generation is deleted.\n",
      "\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageExceptions.createFileNotFoundException(GoogleCloudStorageExceptions.java:47) ~[gcs-connector-3.0.4.jar:?]\n",
      "\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.open(GoogleCloudStorageImpl.java:678) ~[gcs-connector-3.0.4.jar:?]\n",
      "\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.open(GoogleCloudStorageImpl.java:669) ~[gcs-connector-3.0.4.jar:?]\n",
      "\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageFileSystemImpl.open(GoogleCloudStorageFileSystemImpl.java:309) ~[gcs-connector-3.0.4.jar:?]\n",
      "\tat com.google.cloud.hadoop.fs.gcs.GoogleHadoopFSInputStream.create(GoogleHadoopFSInputStream.java:104) ~[gcs-connector-3.0.4.jar:?]\n",
      "\tat com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem.lambda$open$6(GoogleHadoopFileSystem.java:591) ~[gcs-connector-3.0.4.jar:?]\n",
      "\tat org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.invokeTrackingDuration(IOStatisticsBinding.java:547) ~[hadoop-client-api-3.3.6.jar:?]\n",
      "\tat org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.lambda$trackDurationOfOperation$5(IOStatisticsBinding.java:528) ~[hadoop-client-api-3.3.6.jar:?]\n",
      "\tat org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.trackDuration(IOStatisticsBinding.java:449) ~[hadoop-client-api-3.3.6.jar:?]\n",
      "\tat com.google.cloud.hadoop.fs.gcs.GhfsGlobalStorageStatistics.trackDuration(GhfsGlobalStorageStatistics.java:114) ~[gcs-connector-3.0.4.jar:?]\n",
      "\tat com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem.trackDurationWithTracing(GoogleHadoopFileSystem.java:759) ~[gcs-connector-3.0.4.jar:?]\n",
      "\tat com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem.open(GoogleHadoopFileSystem.java:579) ~[gcs-connector-3.0.4.jar:?]\n",
      "\tat org.apache.hadoop.fs.FileSystem.open(FileSystem.java:998) ~[hadoop-client-api-3.3.6.jar:?]\n",
      "\tat org.apache.iceberg.hadoop.HadoopTableOperations.findVersion(HadoopTableOperations.java:317) ~[iceberg-spark-runtime-3.5_2.12-1.7.1.jar:?]\n",
      "\tat org.apache.iceberg.hadoop.HadoopTableOperations.refresh(HadoopTableOperations.java:103) ~[iceberg-spark-runtime-3.5_2.12-1.7.1.jar:?]\n",
      "\tat org.apache.iceberg.hadoop.HadoopTableOperations.current(HadoopTableOperations.java:83) ~[iceberg-spark-runtime-3.5_2.12-1.7.1.jar:?]\n",
      "\tat org.apache.iceberg.BaseTransaction.lambda$commitReplaceTransaction$1(BaseTransaction.java:377) ~[iceberg-spark-runtime-3.5_2.12-1.7.1.jar:?]\n",
      "\tat org.apache.iceberg.util.Tasks$Builder.runTaskWithRetry(Tasks.java:413) ~[iceberg-spark-runtime-3.5_2.12-1.7.1.jar:?]\n",
      "\tat org.apache.iceberg.util.Tasks$Builder.runSingleThreaded(Tasks.java:219) ~[iceberg-spark-runtime-3.5_2.12-1.7.1.jar:?]\n",
      "\tat org.apache.iceberg.util.Tasks$Builder.run(Tasks.java:203) ~[iceberg-spark-runtime-3.5_2.12-1.7.1.jar:?]\n",
      "\tat org.apache.iceberg.util.Tasks$Builder.run(Tasks.java:196) ~[iceberg-spark-runtime-3.5_2.12-1.7.1.jar:?]\n",
      "\tat org.apache.iceberg.BaseTransaction.commitReplaceTransaction(BaseTransaction.java:365) ~[iceberg-spark-runtime-3.5_2.12-1.7.1.jar:?]\n",
      "\tat org.apache.iceberg.BaseTransaction.commitTransaction(BaseTransaction.java:314) ~[iceberg-spark-runtime-3.5_2.12-1.7.1.jar:?]\n",
      "\tat org.apache.iceberg.CommitCallbackTransaction.commitTransaction(CommitCallbackTransaction.java:126) ~[iceberg-spark-runtime-3.5_2.12-1.7.1.jar:?]\n",
      "\tat org.apache.iceberg.spark.source.StagedSparkTable.commitStagedChanges(StagedSparkTable.java:34) ~[iceberg-spark-runtime-3.5_2.12-1.7.1.jar:?]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CreateTableAsSelectBaseExec.$anonfun$writeToTable$1(WriteToDataSourceV2Exec.scala:599) ~[spark-sql_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1399) ~[spark-core_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CreateTableAsSelectBaseExec.writeToTable(WriteToDataSourceV2Exec.scala:592) ~[spark-sql_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CreateTableAsSelectBaseExec.writeToTable$(WriteToDataSourceV2Exec.scala:586) ~[spark-sql_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.AtomicReplaceTableAsSelectExec.writeToTable(WriteToDataSourceV2Exec.scala:185) ~[spark-sql_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.AtomicReplaceTableAsSelectExec.run(WriteToDataSourceV2Exec.scala:218) ~[spark-sql_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43) ~[spark-sql_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43) ~[spark-sql_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49) ~[spark-sql_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125) ~[spark-sql_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201) ~[spark-sql_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108) ~[spark-sql_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66) ~[spark-sql_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:473) ~[spark-catalyst_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76) [spark-sql-api_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:473) [spark-catalyst_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32) [spark-catalyst_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267) [spark-catalyst_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263) [spark-catalyst_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) [spark-catalyst_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) [spark-catalyst_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:449) [spark-catalyst_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98) [spark-sql_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85) [spark-sql_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83) [spark-sql_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142) [spark-sql_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859) [spark-sql_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:634) [spark-sql_2.12-3.5.1.jar:3.5.1]\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:564) [spark-sql_2.12-3.5.1.jar:3.5.1]\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:?]\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566) ~[?:?]\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182) [py4j-0.10.9.7.jar:?]\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106) [py4j-0.10.9.7.jar:?]\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829) [?:?]\n"
     ]
    }
   ],
   "source": [
    "# so far, no cache\n",
    "popularMoviesDf.write\\\n",
    "  .mode(\"overwrite\")\\\n",
    "  .format(\"iceberg\")\\\n",
    "  .saveAsTable(\"iceberg.movielens.popular_movies1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9cf2d621-d1cb-4a24-88c0-9584f3b735e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Sort ['total_ratings DESC NULLS LAST], true\n",
      "+- Project [movieId#87, title#88, avg_rating#199, total_ratings#201L]\n",
      "   +- Join Inner, (movieId#115 = movieId#87)\n",
      "      :- Filter ((total_ratings#201L >= cast(100 as bigint)) AND (avg_rating#199 >= 3.5))\n",
      "      :  +- Sort [total_ratings#201L DESC NULLS LAST], true\n",
      "      :     +- Aggregate [movieId#115], [movieId#115, avg(rating#116) AS avg_rating#199, count(userId#114) AS total_ratings#201L]\n",
      "      :        +- SubqueryAlias iceberg.movielens.ratings\n",
      "      :           +- RelationV2[userId#114, movieId#115, rating#116, timestamp#117L] iceberg.movielens.ratings iceberg.movielens.ratings\n",
      "      +- ResolvedHint (strategy=broadcast)\n",
      "         +- Project [movieId#87, title#88, genres#89]\n",
      "            +- SubqueryAlias iceberg.movielens.movies\n",
      "               +- RelationV2[movieId#87, title#88, genres#89] iceberg.movielens.movies iceberg.movielens.movies\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "movieId: int, title: string, avg_rating: double, total_ratings: bigint\n",
      "Sort [total_ratings#201L DESC NULLS LAST], true\n",
      "+- Project [movieId#87, title#88, avg_rating#199, total_ratings#201L]\n",
      "   +- Join Inner, (movieId#115 = movieId#87)\n",
      "      :- Filter ((total_ratings#201L >= cast(100 as bigint)) AND (avg_rating#199 >= 3.5))\n",
      "      :  +- Sort [total_ratings#201L DESC NULLS LAST], true\n",
      "      :     +- Aggregate [movieId#115], [movieId#115, avg(rating#116) AS avg_rating#199, count(userId#114) AS total_ratings#201L]\n",
      "      :        +- SubqueryAlias iceberg.movielens.ratings\n",
      "      :           +- RelationV2[userId#114, movieId#115, rating#116, timestamp#117L] iceberg.movielens.ratings iceberg.movielens.ratings\n",
      "      +- ResolvedHint (strategy=broadcast)\n",
      "         +- Project [movieId#87, title#88, genres#89]\n",
      "            +- SubqueryAlias iceberg.movielens.movies\n",
      "               +- RelationV2[movieId#87, title#88, genres#89] iceberg.movielens.movies iceberg.movielens.movies\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Sort [total_ratings#201L DESC NULLS LAST], true\n",
      "+- Project [movieId#87, title#88, avg_rating#199, total_ratings#201L]\n",
      "   +- Join Inner, (movieId#115 = movieId#87), rightHint=(strategy=broadcast)\n",
      "      :- Filter ((isnotnull(avg_rating#199) AND (total_ratings#201L >= 100)) AND (avg_rating#199 >= 3.5))\n",
      "      :  +- Aggregate [movieId#115], [movieId#115, avg(rating#116) AS avg_rating#199, count(userId#114) AS total_ratings#201L]\n",
      "      :     +- Filter isnotnull(movieId#115)\n",
      "      :        +- RelationV2[userId#114, movieId#115, rating#116] iceberg.movielens.ratings\n",
      "      +- Filter isnotnull(movieId#87)\n",
      "         +- RelationV2[movieId#87, title#88] iceberg.movielens.movies\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Sort [total_ratings#201L DESC NULLS LAST], true, 0\n",
      "   +- Exchange rangepartitioning(total_ratings#201L DESC NULLS LAST, 1000), ENSURE_REQUIREMENTS, [plan_id=824]\n",
      "      +- Project [movieId#87, title#88, avg_rating#199, total_ratings#201L]\n",
      "         +- BroadcastHashJoin [movieId#115], [movieId#87], Inner, BuildRight, false\n",
      "            :- Filter ((isnotnull(avg_rating#199) AND (total_ratings#201L >= 100)) AND (avg_rating#199 >= 3.5))\n",
      "            :  +- HashAggregate(keys=[movieId#115], functions=[avg(rating#116), count(userId#114)], output=[movieId#115, avg_rating#199, total_ratings#201L])\n",
      "            :     +- Exchange hashpartitioning(movieId#115, 1000), ENSURE_REQUIREMENTS, [plan_id=816]\n",
      "            :        +- HashAggregate(keys=[movieId#115], functions=[partial_avg(rating#116), partial_count(userId#114)], output=[movieId#115, sum#222, count#223L, count#224L])\n",
      "            :           +- Filter isnotnull(movieId#115)\n",
      "            :              +- BatchScan iceberg.movielens.ratings[userId#114, movieId#115, rating#116] iceberg.movielens.ratings (branch=null) [filters=movieId IS NOT NULL, groupedBy=] RuntimeFilters: []\n",
      "            +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=820]\n",
      "               +- Filter isnotnull(movieId#87)\n",
      "                  +- BatchScan iceberg.movielens.movies[movieId#87, title#88] iceberg.movielens.movies (branch=null) [filters=movieId IS NOT NULL, groupedBy=] RuntimeFilters: []\n",
      "\n",
      "Column<'movieId'> Column<'movieId'> Column<'movieId'>\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "broadcastedMoviesDf = F.broadcast(movieDf) # explict, instead of spark optimizer doing\n",
    "# broadcastedMoviesDf used instead of movieDf\n",
    "tempDf = mostPopularMoviesDf.join(broadcastedMoviesDf, mostPopularMoviesDf.movieId == broadcastedMoviesDf.movieId)\\\n",
    "                                     .select(broadcastedMoviesDf.movieId, \"title\", \"avg_rating\", \"total_ratings\")\\\n",
    "                                     .sort(desc(\"total_ratings\"))\n",
    "\n",
    "tempDf.explain(extended = True)\n",
    "\n",
    "print (F.col(\"movieId\"), broadcastedMoviesDf.movieId, movieDf.movieId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "66ea1107-35d8-49fe-8480-e4b573efde2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(movieId=356, avg_rating=4.175304878048781, total_ratings=328),\n",
       " Row(movieId=318, avg_rating=4.429022082018927, total_ratings=317)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mostPopularMoviesDf.rdd.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ab2e40ed-eb0e-45f8-adeb-2628454d3eb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(movieId=1, title='Toy Story (1995)', genres='Adventure|Animation|Children|Comedy|Fantasy'),\n",
       " Row(movieId=2, title='Jumanji (1995)', genres='Adventure|Children|Fantasy')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movieDf.rdd.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1cf533de-3443-4155-80ad-024fb1d191cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/06 07:25:16 WARN HintErrorLogger: A join hint (strategy=broadcast) is specified but it is not part of a join relation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(movieId=1, title='Toy Story (1995)', genres='Adventure|Animation|Children|Comedy|Fantasy'),\n",
       " Row(movieId=2, title='Jumanji (1995)', genres='Adventure|Children|Fantasy')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "broadcastedMoviesDf.rdd.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a7755231-6dc6-41b8-903c-a2455ab5b66b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n  read movies - 100 GB    Input/IO, 10 Sec,    .1 $ bandwidth\\n  read ratings - 1000 GB   Input/IO, 100 Sec, .5 $ bandwidth\\n  analytics on ratings group by, count, avg - Compute - 60 Minutes $$ , Shuffling....\\n  join - shuffle, compute - 1 minute - $\\n   write (format(jdbc)\\n'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write to iceberg table. ACTION, all operations done for a single action\n",
    "# we are reusing dataframe upto the join, then write action different from each other\n",
    "\"\"\"\n",
    "  read movies - 100 GB    Input/IO, 10 Sec,    .1 $ bandwidth\n",
    "  read ratings - 1000 GB   Input/IO, 100 Sec, .5 $ bandwidth\n",
    "  analytics on ratings group by, count, avg - Compute - 60 Minutes $$ , Shuffling....\n",
    "  join - shuffle, compute - 1 minute - $\n",
    "   write (iceberg)\n",
    "\"\"\"\n",
    "\n",
    "# Write to parquet table. ACTION, all operations done for a single action\n",
    "\"\"\"\n",
    "  read movies - 100 GB    Input/IO, 10 Sec,    .1 $ bandwidth\n",
    "  read ratings - 1000 GB   Input/IO, 100 Sec, .5 $ bandwidth\n",
    "  analytics on ratings group by, count, avg - Compute - 60 Minutes $$ , Shuffling....\n",
    "  join - shuffle, compute - 1 minute - $\n",
    "   write (format(parquet)\n",
    "\"\"\"\n",
    "\n",
    "# Write to orc table. ACTION, all operations done for a single action\n",
    "\"\"\"\n",
    "  read movies - 100 GB    Input/IO, 10 Sec,    .1 $ bandwidth\n",
    "  read ratings - 1000 GB   Input/IO, 100 Sec, .5 $ bandwidth\n",
    "  analytics on ratings group by, count, avg - Compute - 60 Minutes $$ , Shuffling....\n",
    "  join - shuffle, compute - 1 minute - $\n",
    "   write (format(orc)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# Write to oracle jdbc table. ACTION, all operations done for a single action\n",
    "\"\"\"\n",
    "  read movies - 100 GB    Input/IO, 10 Sec,    .1 $ bandwidth\n",
    "  read ratings - 1000 GB   Input/IO, 100 Sec, .5 $ bandwidth\n",
    "  analytics on ratings group by, count, avg - Compute - 60 Minutes $$ , Shuffling....\n",
    "  join - shuffle, compute - 1 minute - $\n",
    "   write (format(jdbc)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dd1ce3-56c8-4a97-868c-87219e5bfa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we you see rdd, datafrmae is reused for write, or other downstream operations.. you may cache the reusable dataframe\n",
    "# cache shall be stored in executor MEMORY itself\n",
    "\n",
    "# SPARK USES MEMORY\n",
    "# IF USE MEMORY FOR CACHE, further downstream operations might need memory too, we may face insufficient memory\n",
    "# CACHE - Many options\n",
    "# CACHE - MEMORY, DISK or MEMORY_DISK\n",
    "# CACHE - REPLICAS Available for CACHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d3949d90-7ea8-4d10-81e2-c09acfd3ee98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "popularMoviesDf.cache() # MEMORY_AND_DISK\n",
    "# cache is lazy operation, until an action performed, no cache is applied\n",
    "print (popularMoviesDf.is_cached) # true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aa43a3b9-d7fe-44ce-9a68-208cb543ff1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# so far, NOW IT WILL CACHE popularMoviesDf\n",
    "popularMoviesDf.write\\\n",
    "  .format(\"iceberg\")\\\n",
    "  .saveAsTable(\"iceberg.movielens.popular_movies2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "334d2496-ab98-4cdc-9752-cc5d800ceb28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# so far, it will use the cache\n",
    "popularMoviesDf.write\\\n",
    "  .format(\"iceberg\")\\\n",
    "  .saveAsTable(\"iceberg.movielens.popular_movies3\") # assume you write to other format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b26c0951-2930-4fa5-9f47-621e9888a4fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popularMoviesDf.is_cached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eba5e879-0b89-4548-9ddd-6efb3918d568",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popularMoviesDf.unpersist() # when dataframe cache no longer, ie you may not reuse datafrmae again\n",
    "popularMoviesDf.is_cached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0da6d68-f49e-4120-a3d2-297906cf6abb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}